# ä¿®æ”¹main.pyï¼Œå¤„ç†load_configæŠ›å‡ºçš„å¼‚å¸¸
import argparse
from .api_client import DeepSeekClient
from rich.console import Console
from .utils.models import list_models
from .cli.commands import continuous_chat, single_chat
from .config import get_config_dir_path, get_config_file_path


def config_handler(args):
    """å¤„ç†é…ç½®é€‰é¡¹"""
    from .cli.commands import config_command

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„å‘½åç©ºé—´å¯¹è±¡æ¥æ¨¡æ‹ŸåŸæ¥çš„args
    class ConfigArgs:
        def __init__(self, action, api_key=None):
            self.action = action
            self.api_key = api_key

    config_args = ConfigArgs(args.config_action, args.api_key)
    config_command(config_args)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="Multi LLM Chat In Console.(Using DashScope API)"
    )

    # ä¸»è¦å‚æ•°ï¼šé—®é¢˜
    parser.add_argument("question", nargs="*", help="Input question for AI")

    # æ¨¡å‹é€‰é¡¹
    parser.add_argument(
        "--model", "-m", type=str, default=None, help="Model name or alias"
    )

    # è¿ç»­å¯¹è¯é€‰é¡¹
    parser.add_argument(
        "--continue",
        "-c",
        action="store_true",
        dest="continuous",
        help="Enable continuous conversation mode",
    )

    # é…ç½®ç®¡ç†é€‰é¡¹
    config_group = parser.add_argument_group("é…ç½®ç®¡ç†")
    config_group.add_argument(
        "--config",
        choices=["set", "get", "clear"],
        dest="config_action",
        help="é…ç½®æ“ä½œ: set(è®¾ç½®), get(æŸ¥çœ‹), clear(æ¸…é™¤)",
    )
    config_group.add_argument(
        "--api-key", type=str, help="APIå¯†é’¥ï¼ˆä»…--config setæ—¶ä½¿ç”¨ï¼‰"
    )

    # æ¨¡å‹åˆ—è¡¨é€‰é¡¹
    parser.add_argument(
        "--list-models",
        "-l",
        action="store_true",
        help="List all supported model aliases",
    )

    args = parser.parse_args()
    console = Console()

    # å¤„ç†é…ç½®å‘½ä»¤ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    if args.config_action:
        config_handler(args)
        return

    # å¦‚æœè¯·æ±‚åˆ—å‡ºæ¨¡å‹ï¼Œåˆ™æ˜¾ç¤ºæ¨¡å‹åˆ—è¡¨å¹¶é€€å‡º
    if args.list_models:
        list_models()
        return

    # ä¸»èŠå¤©åŠŸèƒ½
    try:
        client = DeepSeekClient()
    except ValueError as e:
        # å¤„ç†ç¼ºå°‘APIå¯†é’¥çš„æƒ…å†µ
        console.print(f"[red]âœ–ï¸ {str(e)}[/red]")
        console.print(f"[cyan]ğŸ“ é…ç½®ç›®å½•: {get_config_dir_path()}[/cyan]")
        console.print(f"[cyan]ğŸ“„ é…ç½®æ–‡ä»¶: {get_config_file_path()}[/cyan]")
        return

    # åˆ¤æ–­æ˜¯å¦å¯ç”¨è¿ç»­å¯¹è¯
    if args.continuous or not args.question:
        # è¿ç»­å¯¹è¯æ¨¡å¼
        initial_question = " ".join(args.question) if args.question else None
        continuous_chat(client, console, args.model, initial_question)
    else:
        # å•æ¬¡å¯¹è¯æ¨¡å¼
        question = " ".join(args.question)
        single_chat(client, console, question, args.model)


if __name__ == "__main__":
    main()
