# chat/interface.py
from rich.panel import Panel
from rich.markdown import Markdown
from rich.live import Live
import re


class ChatInterface:
    """èŠå¤©ç•Œé¢ç®¡ç†ç±»"""

    def __init__(self, client, console):
        self.client = client
        self.console = console
        self.system_prompt = "(å¦‚æœæœªæŒ‡å®šè¯­è¨€ï¼Œå›å¤ç­”æ¡ˆæ—¶è¯·ä½¿ç”¨ä¸­æ–‡è¯­è¨€)"

    def display_question(self, question):
        """æ˜¾ç¤ºé—®é¢˜"""
        self.console.print(
            Panel.fit(
                f"[bold cyan]{question}[/bold cyan]",
                title="[bold blue]QuestionğŸ’­[/bold blue]",
                border_style="blue",
            )
        )

    def display_streaming_response(self, response_stream):
        """åŠ¨æ€æ˜¾ç¤ºæµå¼AIå›å¤"""
        self.console.print("\n[bold green]ğŸ¤–:[/bold green]")

        full_response = ""
        with Live(refresh_per_second=10) as live:
            for chunk in response_stream:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    full_response += content

                    # åŠ¨æ€æ›´æ–°Markdownæ˜¾ç¤º
                    processed_response = self._preprocess_response(full_response)
                    markdown = Markdown(processed_response)
                    live.update(markdown)

        return full_response

    def display_response(self, response):
        """æ˜¾ç¤ºAIå›å¤"""
        self.console.print("\n[bold green]ğŸ¤–:[/bold green]")

        if response is None:
            self.console.print("[yellow]âœ–ï¸æ¨¡å‹è¿”å›äº†ç©ºå“åº”ã€‚[/yellow]")
        else:
            # é¢„å¤„ç†å“åº”ï¼Œç¡®ä¿ä»£ç å—æ­£ç¡®æ¸²æŸ“
            processed_response = self._preprocess_response(response)
            markdown = Markdown(processed_response)
            self.console.print(markdown)

    def _preprocess_response(self, response):
        """é¢„å¤„ç†å“åº”ï¼Œç¡®ä¿ä»£ç å—æ­£ç¡®æ¸²æŸ“"""
        # ç¡®ä¿ä»£ç å—æœ‰æ­£ç¡®çš„è¯­è¨€æ ‡è¯†
        response = re.sub(r"```(\w*)", r"```\1\n", response)
        response = re.sub(r"```\n", r"\n```\n", response)
        return response

    def call_api_single(self, question, model=None):
        """å•æ¬¡APIè°ƒç”¨ - åŠ¨æ€æµå¼è¾“å‡º"""
        question_with_lang = question + self.system_prompt

        # è·å–æµå¼å“åº”ï¼ˆä¸æ˜¾ç¤ºæ€è€ƒä¸­ï¼‰
        actual_model = (
            self.client.resolve_model_name(model)
            if model
            else self.client.config["default_model"]
        )

        response = self.client.client.chat.completions.create(
            model=actual_model,
            messages=[{"role": "user", "content": question_with_lang}],
            stream=True,
        )

        # åŠ¨æ€æ˜¾ç¤ºæµå¼å“åº”
        return self.display_streaming_response(response)

    def call_api_continuous(self, messages, model=None):
        """è¿ç»­å¯¹è¯APIè°ƒç”¨ - åŠ¨æ€æµå¼è¾“å‡º"""
        # è·å–æµå¼å“åº”ï¼ˆä¸æ˜¾ç¤ºæ€è€ƒä¸­ï¼‰
        actual_model = (
            self.client.resolve_model_name(model)
            if model
            else self.client.config["default_model"]
        )

        response = self.client.client.chat.completions.create(
            model=actual_model,
            messages=messages,
            stream=True,
        )

        # åŠ¨æ€æ˜¾ç¤ºæµå¼å“åº”
        return self.display_streaming_response(response)
